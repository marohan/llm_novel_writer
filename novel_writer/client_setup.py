import requests
from typing import List, Dict, Optional, Tuple
import numpy as np
from novel_writer.writer_config import WriterConfig

# Google Generative AI SDK import
try:
    from google import genai
    from google.genai import types
    from google.genai.errors import APIError
except ImportError:
    print("âš ï¸ 'google-genai' íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install google-genai numpy'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    exit()


# ============================================================================
# API Clients
# ============================================================================

class GroqClient:
    """Groq API Client"""

    def __init__(self, config: WriterConfig):
        self.config = config
        self.base_url = "https://api.groq.com/openai/v1"

    def generate(self, model: str, prompt: str, system: str = "",
                 temperature: float = 0.7, format_json: bool = False,
                 max_tokens: Optional[int] = None, reasoning_format: str = "hidden") -> str:

        url = f"{self.base_url}/chat/completions"

        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        messages.append({"role": "user", "content": prompt})

        data = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens or self.config.max_generation_tokens,
            "reasoning_format": reasoning_format
        }

        if format_json:
            data["response_format"] = {"type": "json_object"}

        headers = {
            "Authorization": f"Bearer {self.config.api_key}",
            "Content-Type": "application/json"
        }

        response = requests.post(url, json=data, headers=headers, timeout=300)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]

    def get_embedding(self, text: str) -> np.ndarray:
        """ì„ë² ë”© ìƒì„± (fallback í¬í•¨)"""
        try:
            url = f"{self.base_url}/embeddings"

            data = {
                "model": self.config.embedding_model,
                "input": text[:8000]
            }

            headers = {
                "Authorization": f"Bearer {self.config.api_key}",
                "Content-Type": "application/json"
            }

            response = requests.post(url, json=data, headers=headers, timeout=60)
            response.raise_for_status()

            embedding = response.json()["data"][0]["embedding"]
            return np.array(embedding, dtype=np.float32)

        except Exception as e:
            print(f"  âš ï¸ Embedding API ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}")
            vector_dim = 768
            vector = np.zeros(vector_dim, dtype=np.float32)
            return vector


class GroqClient:
    """Groq API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, config: WriterConfig):
        self.config = config
        self.base_url = "https://api.groq.com/openai/v1"

    def generate(self, model: str, prompt: str, system: str = "",
                 temperature: float = 0.7, format_json: bool = False,
                 max_tokens: Optional[int] = None, reasoning_format: str = "hidden") -> str:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        url = f"{self.base_url}/chat/completions"

        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        messages.append({"role": "user", "content": prompt})

        data = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens or self.config.max_generation_tokens,
            "reasoning_format": reasoning_format
        }

        if format_json:
            data["response_format"] = {"type": "json_object"}

        headers = {
            "Authorization": f"Bearer {self.config.api_key}",
            "Content-Type": "application/json"
        }

        response = requests.post(url, json=data, headers=headers, timeout=300)
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"]

    def get_embedding(self, text: str) -> np.ndarray:
        """ì„ë² ë”© ìƒì„± (fallback í¬í•¨)"""
        try:
            url = f"{self.base_url}/embeddings"

            data = {
                "model": self.config.embedding_model,
                "input": text[:8000]
            }

            headers = {
                "Authorization": f"Bearer {self.config.api_key}",
                "Content-Type": "application/json"
            }

            response = requests.post(url, json=data, headers=headers, timeout=60)
            response.raise_for_status()

            embedding = response.json()["data"][0]["embedding"]
            return np.array(embedding, dtype=np.float32)

        except Exception as e:
            print(f"  âš ï¸ Embedding API ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}")
            vector_dim = 768
            vector = np.zeros(vector_dim, dtype=np.float32)
            return vector

class GeminiClient:
    """Gemini API Client """

    def __init__(self, config: WriterConfig):
        self.config = config

        api_key = self.config.api_key if hasattr(self.config, 'api_key') else None

        self.client = genai.Client(api_key=api_key)

    def generate(self, model: str, prompt: str, system: str = "",
                 temperature: float = 0.7, format_json: bool = False,
                 max_tokens: Optional[int] = None, **kwargs) -> str:

        contents: List[types.Content] = []

        user_parts = [types.Part(text=prompt)]
        contents.append(types.Content(role="user", parts=user_parts))

        config_params: Dict[str, Any] = {
            "temperature": temperature,
            "max_output_tokens": max_tokens or self.config.max_generation_tokens,
        }

        if system:
            config_params["system_instruction"] = system

        if format_json:
            config_params["response_mime_type"] = "application/json"

        try:
            response = self.client.models.generate_content(
                model=model,
                contents=contents,
                config=types.GenerateContentConfig(**config_params)
            )

            return response.text

        except APIError as e:
            print(f"âš ï¸ Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise
        except Exception as e:
            print(f"âš ï¸ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def get_embedding(self, text: str) -> np.ndarray:
        """ì„ë² ë”© ìƒì„± (fallback í¬í•¨)"""

        model_name = self.config.embedding_model

        try:
            # 1. API í˜¸ì¶œ
            response = self.client.models.embed_content(
                model=model_name,
                content=text,
                task_type="RETRIEVAL_DOCUMENT"
            )

            # 2. ê²°ê³¼ ë°˜í™˜
            # ì‘ë‹µ ê°ì²´ì—ì„œ ì„ë² ë”© ë²¡í„°ë¥¼ .embedding ì†ì„±ìœ¼ë¡œ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
            # ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„: response['embedding'] -> response.embedding
            embedding = response.embedding
            return np.array(embedding, dtype=np.float32)

        except APIError as e:
            # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
            print(f"  âš ï¸ Embedding API ì‹¤íŒ¨: {e}")

            # 3. Fallback ì²˜ë¦¬
            vector_dim = 768  # 'text-embedding-004'ì˜ ì°¨ì›ì€ 768ì…ë‹ˆë‹¤.
            vector = np.zeros(vector_dim, dtype=np.float32)
            return vector
        except Exception as e:
            # ì˜ˆê¸°ì¹˜ ì•Šì€ ë‹¤ë¥¸ ì˜¤ë¥˜ ë°œìƒ ì‹œ
            print(f"  âš ï¸ Embedding ì²˜ë¦¬ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ, fallback ì‚¬ìš©: {e}")
            vector_dim = 768
            vector = np.zeros(vector_dim, dtype=np.float32)
            return vector